spring.application.name=cheese

# Default database configuration
# If you follow README.md and use docker to setup the database, this configuration should work
spring.datasource.url=jdbc:postgresql://localhost:5432/postgres
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.show-sql=true
spring.jpa.hibernate.ddl-auto=validate

# Default ElasticSearch configuration
# If you follow README.md and use docker to setup the database, this configuration should work, too
spring.elasticsearch.uris=http://localhost:9200
spring.elasticsearch.username=elastic
spring.elasticsearch.password=elastic

# Redis Configuration
spring.data.redis.host=localhost
spring.data.redis.port=6379
spring.data.redis.database=0
spring.data.redis.timeout=10000

application.legacy-url=http://localhost:7777
application.jwt-secret=test-secret
application.cors-origin=http://localhost:3000
application.warn-audit-failure=true

# These configurations define how rank check is performed when user joins a task
# If rank-check-enforced is false, such a check is disabled completely.
# If rank-check-enforced is true, user with rank N can only join tasks whose rank <= N + rank-jump
application.rank-check-enforced=true
application.rank-jump=1

application.enforce-task-participant-limit-check=true
application.auto-reject-participant-after-reaches-limit=true

# To disable such a warning:
# spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering.
# Explicitly configure spring.jpa.open-in-view to disable this warning
#
# According to our test, disable this configuration will cause JPA to not work at all.
# So, we enable it here.
spring.jpa.open-in-view=true

# LLM Configuration
cheese.llm.api-key=${OPENAI_API_KEY}
cheese.llm.base-url=${OPENAI_BASE_URL}

# Configurations for different models
cheese.llm.models.standard.name=bot-20250223230745-8shdk
cheese.llm.models.standard.temperature=0.7
cheese.llm.models.standard.max-tokens=2000
cheese.llm.models.standard.top-p=1.0
# cheese.llm.models.standard.frequency-penalty=0.0
# cheese.llm.models.standard.presence-penalty=0.0

cheese.llm.models.reasoning.name=bot-20250225164439-vld75
cheese.llm.models.reasoning.temperature=0.6
cheese.llm.models.reasoning.max-tokens=2000
cheese.llm.models.reasoning.top-p=1.0

cheese.llm.models.light.name=bot-20250226105936-6klx4
cheese.llm.models.light.temperature=0.6
cheese.llm.models.light.max-tokens=500
cheese.llm.models.light.top-p=1.0

# Default model type
cheese.llm.default-model-type=standard

# LLM Timeout Configuration
cheese.llm.timeout.socket=${OPENAI_SOCKET_TIMEOUT:60}
cheese.llm.timeout.connect=${OPENAI_CONNECT_TIMEOUT:60}
cheese.llm.timeout.request=${OPENAI_REQUEST_TIMEOUT:600}

# AI Quota Configuration
cheese.llm.quota.default-daily-quota=20
cheese.llm.quota.reset-hour=4
cheese.llm.quota.reset-minute=0
cheese.llm.quota.standard-token-ratio=0.5
cheese.llm.quota.advanced-token-ratio=1.0
cheese.llm.quota.cache-reuse-ratio=0.1
cheese.llm.quota.cold-content-cache-days=365
cheese.llm.quota.regular-content-cache-days=30