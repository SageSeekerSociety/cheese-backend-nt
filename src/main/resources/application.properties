spring.application.name=cheese

# Default database configuration
# If you follow README.md and use docker to setup the database, this configuration should work
spring.datasource.url=jdbc:postgresql://localhost:5432/postgres
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.show-sql=true
spring.jpa.hibernate.ddl-auto=validate

# Default ElasticSearch configuration
# If you follow README.md and use docker to setup the database, this configuration should work, too
spring.elasticsearch.uris=http://localhost:9200
spring.elasticsearch.username=elastic
spring.elasticsearch.password=elastic

# Redis Configuration
spring.redis.host=localhost
spring.redis.port=6379
spring.redis.database=0
spring.redis.timeout=10000

application.legacy-url=http://localhost:7777
application.jwt-secret=test-secret
application.cors-origin=http://localhost:3000
application.warn-audit-failure=true

# These configurations define how rank check is performed when user joins a task
# If rank-check-enforced is false, such a check is disabled completely.
# If rank-check-enforced is true, user with rank N can only join tasks whose rank <= N + rank-jump
application.rank-check-enforced=true
application.rank-jump=1

application.enforce-task-participant-limit-check=true
application.auto-reject-participant-after-reaches-limit=true

# To disable such a warning:
# spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering.
# Explicitly configure spring.jpa.open-in-view to disable this warning
#
# According to our test, disable this configuration will cause JPA to not work at all.
# So, we enable it here.
spring.jpa.open-in-view=true

# LLM Configuration
cheese.llm.api-key=${OPENAI_API_KEY}
cheese.llm.base-url=${OPENAI_BASE_URL:https://api.openai.com/v1}
cheese.llm.model.name=${OPENAI_MODEL:gpt-3.5-turbo}
cheese.llm.model.temperature=${OPENAI_TEMPERATURE:0.7}
cheese.llm.model.max-tokens=${OPENAI_MAX_TOKENS:2000}
cheese.llm.model.top-p=1.0
cheese.llm.model.frequency-penalty=0.0
cheese.llm.model.presence-penalty=0.0

# LLM Timeout Configuration
cheese.llm.timeout.socket=${OPENAI_SOCKET_TIMEOUT:60}
cheese.llm.timeout.connect=${OPENAI_CONNECT_TIMEOUT:60}
cheese.llm.timeout.request=${OPENAI_REQUEST_TIMEOUT:600}

# AI Quota Configuration
cheese.llm.quota.default-daily-quota=20
cheese.llm.quota.reset-hour=4
cheese.llm.quota.reset-minute=0